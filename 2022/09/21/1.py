# 传统的网络需要大量的参数，
# 但是这些参数是否重复了呢，
# 例如，我们识别一个人，
# 只要看到他的眼睛，鼻子，嘴，还有脸基本上就知道这个人是谁了，
# 只是用这些局部的特征就能做做判断了，
# 并不需要所有的特征。
# 另外一点就是我们上面说的可以有效提取了输入图像的平移不变特征，
# 就好像我们看到了这是个眼睛，
# 这个眼镜在左边还是在右边他都是眼睛，
# 这就是平移不变性。
# 我们通过卷积的计算操作来提取图像局部的特征，
# 每一层都会计算出一些局部特征，
# 这些局部特征再汇总到下一层，
# 这样一层一层的传递下去，
# 特征由小变大，
# 最后在通过这些局部的特征对图片进行处理，
# 这样大大提高了计算效率，也提高了准确度。

import torchvision
model = torchvision.models.alexnet(pretrained=False)
print(model)

# 卷积层每一维度大小计算方法 output=(input-kernel+padding*2+stride)/stride


# googlenet最大的特点就是包含若干个inception模块，
# 所以有时候也称作 inception net。
# googlenet虽然层数要比VGG多很多，但是由于inception的设计，计算速度方面要快很多。

# Inception架构的主要思想是找出如何让已有的稠密组件接近与覆盖卷积视觉网络中的最佳局部稀疏结构。
# 现在需要找出最优的局部构造，并且重复几次。
# 之前的一篇文献提出一个层与层的结构，在最后一层进行相关性统计，将高相关性的聚集到一起。
# 这些聚类构成下一层的单元，且与上一层单元连接。假设前面重登层的每个单元对应于输入图像的某些区域，这些单元被分为滤波器组。在接近输入层的低层中，相关单元集中在某些局部区域，最终得到在单个区域中的大量聚类，在最后一层通过1x1的卷积覆盖。

# bn层
# batch normalization layer
#BN的基本思想其实相当直观：
# 因为深层神经网络在做非线性变换前的输入值（y=Wx+B，x是输入）随着网络深度加深或者在训练过程中，
# 其分布逐渐发生偏移或者变动，之所以训练收敛慢，
# 一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近，
# 所以这导致反向传播时低层神经网络的梯度消失，
# 这是训练深层神经网络收敛越来越慢的本质原因，
# 而BN就是通过一定的规范化手段，
# 把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，
# 其实就是把越来越偏的分布强制拉回比较标准的分布，
# 这样使得激活输入值落在非线性函数对输入比较敏感的区域，
# 网络的输出就不会很大，可以得到比较大的梯度，避免梯度消失问题产生，
# 而且梯度变大意味着学习收敛速度快，能大大加快训练速度。

# Parameters
# num_features：图像的通道数，也即(N, C, H, W)中的C的值
# eps：增加至分母上的一个很小的数，为了防止/0情况的发生
# momentum：用来计算平均值和方差的值，默认值为0.1
# affine：一个布尔类型的值，当设置为True的时候，该模型对affine参数具有可学习的能力，默认为True
# track_running_stats：一个布尔类型的值，用于记录均值和方差，当设置为True的时候，模型会跟踪均值和方差，反之，不会跟踪均值和方差
# Shape
# Input: (N, C, H, W)
# Output: (N, C, H, W)
import torch
torch.nn.BatchNorm2d(num_features=100)

# Residual net(残差网络)：
# 将靠前若干层的某一层数据输出直接跳过多层引入到后面数据层的输入部分。
# 意味着后面的特征层的内容会有一部分由其前面的某一层线性贡献。 减缓了梯度消失的问题

# orch.nn.BatchNorm2d对每一特征通道进行normalize，
# 因此会计算出所有样本每一通道的均值和方差
model = torchvision.models.resnet18(pretrained=False)
print(model)
